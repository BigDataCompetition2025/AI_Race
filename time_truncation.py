# === ç«¶è³½è³‡æ–™æ™‚é–“æˆªæ–·è™•ç† ===
import pandas as pd
import numpy as np
import glob
import os
from pathlib import Path

def truncate_overtime_data(csv_file_path, condition_map):
    """
    æ ¹æ“šåŠ å·¥æ¢ä»¶æˆªæ–·è¶…æ™‚è³‡æ–™
    
    Parameters:
    - csv_file_path: CSV æª”æ¡ˆè·¯å¾‘
    - condition_map: åŠ å·¥æ¢ä»¶å°ç…§è¡¨
    
    Returns:
    - truncated_df: æˆªæ–·å¾Œçš„ DataFrame
    - truncation_info: æˆªæ–·è³‡è¨Š
    """
    
    # è¼‰å…¥åŸå§‹è³‡æ–™
    df = pd.read_csv(csv_file_path, low_memory=False)
    filename = os.path.basename(csv_file_path)
    
    try:
        # å¾æª”åæå–æ—¥æœŸ
        date_str = filename.split('_')[1]
        condition = condition_map.get(date_str, {})
        
        if not condition:
            print(f"âš ï¸ æ‰¾ä¸åˆ° {filename} çš„åŠ å·¥æ¢ä»¶ï¼Œè·³éæˆªæ–·")
            return df, {'truncated': False, 'reason': 'no_condition_info'}
        
        # è¨ˆç®—ç¸½åŠ å·¥æ™‚é–“
        total_hours = 0
        stage_times = []
        
        # ç¬¬ä¸€æ®µæ™‚é–“
        if 'time1' in condition or pd.notna(condition.get('time1', np.nan)):
            stage1_time = condition.get('time1', 0)
            stage_times.append(stage1_time)
            total_hours += stage1_time
        
        # ç¬¬äºŒæ®µæ™‚é–“  
        if 'time2' in condition or pd.notna(condition.get('time2', np.nan)):
            stage2_time = condition.get('time2', 0)
            stage_times.append(stage2_time)
            total_hours += stage2_time
            
        # ç¬¬ä¸‰æ®µæ™‚é–“
        if 'time3' in condition or pd.notna(condition.get('time3', np.nan)):
            stage3_time = condition.get('time3', 0)
            stage_times.append(stage3_time)
            total_hours += stage3_time
        
        # å¦‚æœç„¡æ³•å–å¾—æ™‚é–“è³‡è¨Šï¼Œä½¿ç”¨é è¨­å€¼
        if total_hours == 0:
            # å¾åŠ å·¥æ¢ä»¶è¡¨æ‰‹å‹•æŸ¥è©¢
            total_hours = estimate_total_time_from_filename(filename)
        
        print(f"ğŸ“‹ {filename}: è¨ˆåŠƒåŠ å·¥æ™‚é–“ = {total_hours} å°æ™‚")
        
        # å‡è¨­å–æ¨£é »ç‡ (éœ€è¦æ ¹æ“šå¯¦éš›è³‡æ–™èª¿æ•´)
        if 'Time' in df.columns:
            # ä½¿ç”¨ Time æ¬„ä½è¨ˆç®—
            time_values = pd.to_numeric(df['Time'], errors='coerce')
            max_time_seconds = total_hours * 3600  # è½‰æ›ç‚ºç§’
            
            # æ‰¾åˆ°æˆªæ–·é»
            valid_mask = time_values <= max_time_seconds
            truncate_index = valid_mask.sum()
            
        else:
            # ä½¿ç”¨è¡Œæ•¸ä¼°ç®— (å‡è¨­å›ºå®šå–æ¨£é »ç‡)
            sampling_rate_per_hour = estimate_sampling_rate(df, total_hours)
            expected_rows = int(total_hours * sampling_rate_per_hour)
            truncate_index = min(expected_rows, len(df))
        
        # åŸ·è¡Œæˆªæ–·
        if truncate_index < len(df):
            truncated_df = df.iloc[:truncate_index].copy()
            truncation_info = {
                'truncated': True,
                'original_rows': len(df),
                'truncated_rows': truncate_index,
                'removed_rows': len(df) - truncate_index,
                'planned_hours': total_hours,
                'truncate_reason': 'overtime_data_removal'
            }
            print(f"âœ‚ï¸  æˆªæ–· {filename}: {len(df)} â†’ {truncate_index} è¡Œ (ç§»é™¤ {len(df) - truncate_index} è¡Œ)")
        else:
            truncated_df = df.copy()
            truncation_info = {
                'truncated': False,
                'original_rows': len(df),
                'planned_hours': total_hours,
                'truncate_reason': 'no_overtime_data'
            }
            print(f"âœ… {filename}: ç„¡éœ€æˆªæ–· ({len(df)} è¡Œ)")
        
        return truncated_df, truncation_info
        
    except Exception as e:
        print(f"âŒ è™•ç† {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return df, {'truncated': False, 'reason': f'error: {e}'}

def estimate_total_time_from_filename(filename):
    """å¾æª”åæ¨ä¼°ç¸½åŠ å·¥æ™‚é–“"""
    
    # æ‰‹å‹•å°ç…§è¡¨ (æ ¹æ“šæª”æ¡ˆç’°å¢ƒè¨­å®šç¸½è¡¨)
    time_mapping = {
        '20200615': 5.0,   # 2000rpm, 5H
        '20200616': 5.0,   # 1000rpm, 5H  
        '20200617': 5.0,   # 1000rpm 2.5H + 2000rpm 2.5H
        '20200618': 5.0,   # 2000rpm 2.5H + 1000rpm 2.5H
        '20200701': 5.0,   # 2000rpm, 5H
        '20200702': 5.0,   # 1000rpm, 5H
        '20200703': 5.0,   # 1000rpm 2.5H + 2000rpm 2.5H
        '20200706': 5.0,   # 2000rpm 2.5H + 1000rpm 2.5H
        '20200708': 6.0,   # 2000rpm, 6H (è®Šæº«)
        '20200709': 6.0,   # 1000rpm, 6H (è®Šæº«)
        '20200710': 6.0,   # 1000rpm 3H + 2000rpm 3H (è®Šæº«)
        '20200713': 6.0,   # 2000rpm 3H + 1000rpm 3H (è®Šæº«)
        '20200715': 6.0,   # 1800rpm 2.5H + åœæ©Ÿ 1H + 1200rpm 2.5H
        # ... å…¶ä»–æ—¥æœŸ
    }
    
    date_part = filename.split('_')[1] if '_' in filename else ''
    return time_mapping.get(date_part, 5.0)  # é è¨­ 5 å°æ™‚

def estimate_sampling_rate(df, total_hours):
    """ä¼°ç®—å–æ¨£é »ç‡"""
    
    # æ–¹æ³•1: ä½¿ç”¨ Time æ¬„ä½
    if 'Time' in df.columns:
        time_values = pd.to_numeric(df['Time'], errors='coerce').dropna()
        if len(time_values) > 1:
            max_time_seconds = time_values.max()
            sampling_rate = len(time_values) / (max_time_seconds / 3600)  # æ¯å°æ™‚æ¨£æœ¬æ•¸
            return sampling_rate
    
    # æ–¹æ³•2: å‡è¨­å›ºå®šå–æ¨£é »ç‡
    # æ ¹æ“šç¾æœ‰è³‡æ–™æ¨ä¼° (ä¾‹å¦‚: æ¯åˆ†é˜1ç­†)
    estimated_rate_per_hour = 60  # æ¯å°æ™‚60ç­†
    return estimated_rate_per_hour

def batch_truncate_files(train_dir, condition_map, output_dir=None):
    """æ‰¹æ¬¡è™•ç†æ‰€æœ‰æª”æ¡ˆçš„æ™‚é–“æˆªæ–·"""
    
    if output_dir:
        Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    train_files = sorted(glob.glob(os.path.join(train_dir, "*.csv")))
    truncation_summary = []
    
    print(f"=== ğŸ“‚ æ‰¹æ¬¡æˆªæ–·è™•ç†: {len(train_files)} å€‹æª”æ¡ˆ ===")
    
    for file_path in train_files:
        filename = os.path.basename(file_path)
        
        # åŸ·è¡Œæˆªæ–·
        truncated_df, info = truncate_overtime_data(file_path, condition_map)
        
        # å„²å­˜è™•ç†å¾Œçš„æª”æ¡ˆ
        if output_dir:
            output_path = os.path.join(output_dir, filename)
            truncated_df.to_csv(output_path, index=False)
        
        # è¨˜éŒ„è™•ç†çµæœ
        info['filename'] = filename
        truncation_summary.append(info)
    
    # é¡¯ç¤ºè™•ç†æ‘˜è¦
    summary_df = pd.DataFrame(truncation_summary)
    
    print(f"\n=== ğŸ“Š æˆªæ–·è™•ç†æ‘˜è¦ ===")
    truncated_count = summary_df['truncated'].sum()
    total_removed = summary_df['removed_rows'].sum() if 'removed_rows' in summary_df.columns else 0
    
    print(f"ğŸ“‹ è™•ç†æª”æ¡ˆç¸½æ•¸: {len(summary_df)}")
    print(f"âœ‚ï¸  æˆªæ–·æª”æ¡ˆæ•¸: {truncated_count}")
    print(f"ğŸ“‰ ç¸½ç§»é™¤è¡Œæ•¸: {total_removed:,}")
    print(f"ğŸ’¾ å¹³å‡ç§»é™¤æ¯”ä¾‹: {(total_removed / summary_df['original_rows'].sum() * 100):.1f}%")
    
    # é¡¯ç¤ºéœ€è¦æˆªæ–·çš„æª”æ¡ˆ
    if truncated_count > 0:
        truncated_files = summary_df[summary_df['truncated'] == True]
        print(f"\nâš ï¸  éœ€è¦æˆªæ–·çš„æª”æ¡ˆ:")
        for _, row in truncated_files.iterrows():
            removal_pct = (row['removed_rows'] / row['original_rows'] * 100)
            print(f"   {row['filename']}: ç§»é™¤ {row['removed_rows']} è¡Œ ({removal_pct:.1f}%)")
    
    return summary_df

# === ä½¿ç”¨ç¯„ä¾‹ ===
if __name__ == "__main__":
    
    # è¼‰å…¥æ¢ä»¶å°ç…§è¡¨
    from smart_data_split import load_condition_mapping  # ä½¿ç”¨ä¹‹å‰çš„å‡½æ•¸
    condition_map = load_condition_mapping()
    
    # è¨­å®šè·¯å¾‘
    TRAIN_DIR = "/Users/benjamin/1132/11325/AI_Race/2025_dataset_0806 3/train"
    OUTPUT_DIR = "/Users/benjamin/1132/11325/AI_Race/truncated_data"
    
    # åŸ·è¡Œæ‰¹æ¬¡æˆªæ–·
    summary = batch_truncate_files(TRAIN_DIR, condition_map, OUTPUT_DIR)
    
    # å„²å­˜è™•ç†å ±å‘Š
    report_file = f"{OUTPUT_DIR}/truncation_report.csv"
    summary.to_csv(report_file, index=False)
    print(f"\nğŸ“„ è™•ç†å ±å‘Šå·²å„²å­˜: {report_file}")
