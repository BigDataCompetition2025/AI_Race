"""
åˆ†å€RMSEåˆ†ææ¸¬è©¦ç¨‹å¼
å°ˆé–€æ¸¬è©¦ä¸‰ç¨®æ¨¡å‹çš„åˆ†å€æ€§èƒ½ï¼Œè­˜åˆ¥æ¥µç«¯æƒ…æ³
"""

import pandas as pd
import numpy as np
import os
import glob
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
plt.rcParams['axes.unicode_minus'] = False

def load_and_prepare_data():
    """è¼‰å…¥ä¸¦æº–å‚™è³‡æ–™"""
    data_path = r"d:\Github\BigDataCompetition\2025_dataset_0806_x893\2025_dataset_0806\train"
    
    # è¼‰å…¥è³‡æ–™
    csv_files = glob.glob(os.path.join(data_path, "*.csv"))
    all_data = []
    
    for file_path in csv_files[:10]:  # åªç”¨å‰10å€‹æª”æ¡ˆå¿«é€Ÿæ¸¬è©¦
        try:
            df = pd.read_csv(file_path)
            all_data.append(df)
        except:
            pass
    
    data = pd.concat(all_data, ignore_index=True)
    
    # æº–å‚™ç‰¹å¾µ
    time_features = ['Time']
    pt_features = [f'PT{i:02d}' for i in range(1, 14)]
    tc_features = [f'TC{i:02d}' for i in range(1, 9)]
    motor_temp_features = ['Spindle Motor', 'X Motor', 'Z Motor']
    
    feature_columns = time_features + pt_features + tc_features + motor_temp_features
    feature_columns = [col for col in feature_columns if col in data.columns]
    target_columns = ['Disp. X', 'Disp. Z']
    
    # è™•ç†ç¼ºå¤±å€¼
    for col in feature_columns + target_columns:
        if data[col].isnull().sum() > 0:
            data[col] = data[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')
    
    return data, feature_columns, target_columns

def segmented_rmse_analysis(X_test, y_test, y_pred_X, y_pred_Z, model_name):
    """åˆ†å€RMSEåˆ†æ"""
    print(f"\n=== {model_name} åˆ†å€RMSEåˆ†æ ===")
    
    results = {}
    
    # 1. æŒ‰è®Šä½å¤§å°åˆ†å€
    print("\n1. æŒ‰è®Šä½å¤§å°åˆ†å€:")
    for axis, actual, pred in [('X', y_test['Disp. X'], y_pred_X), 
                               ('Z', y_test['Disp. Z'], y_pred_Z)]:
        percentiles = [0, 25, 50, 75, 100]
        range_boundaries = np.percentile(actual, percentiles)
        
        for i in range(len(percentiles)-1):
            mask = (actual >= range_boundaries[i]) & (actual < range_boundaries[i+1])
            if i == len(percentiles)-2:
                mask = actual >= range_boundaries[i]
            
            if mask.sum() > 0:
                rmse = np.sqrt(mean_squared_error(actual[mask], pred[mask]))
                count = mask.sum()
                range_name = f"P{percentiles[i]}-P{percentiles[i+1]}"
                print(f"  {axis}è»¸ {range_name}: RMSE={rmse:.4f} Î¼m, æ¨£æœ¬æ•¸={count}")
    
    # 2. æŒ‰æº«åº¦åˆ†å€
    print("\n2. æŒ‰ä¸»è»¸é¦¬é”æº«åº¦åˆ†å€:")
    spindle_temp = X_test['Spindle Motor']
    temp_boundaries = np.percentile(spindle_temp, [0, 33, 67, 100])
    temp_labels = ['ä½æº«', 'ä¸­æº«', 'é«˜æº«']
    
    for axis, actual, pred in [('X', y_test['Disp. X'], y_pred_X), 
                               ('Z', y_test['Disp. Z'], y_pred_Z)]:
        for i, label in enumerate(temp_labels):
            if i < len(temp_labels) - 1:
                mask = (spindle_temp >= temp_boundaries[i]) & (spindle_temp < temp_boundaries[i+1])
            else:
                mask = spindle_temp >= temp_boundaries[i]
            
            if mask.sum() > 0:
                rmse = np.sqrt(mean_squared_error(actual[mask], pred[mask]))
                count = mask.sum()
                print(f"  {axis}è»¸ {label}({temp_boundaries[i]:.1f}Â°C): RMSE={rmse:.4f} Î¼m, æ¨£æœ¬æ•¸={count}")
    
    # 3. æ¥µç«¯å€¼åˆ†æ
    print("\n3. æ¥µç«¯å€¼åˆ†æ (å‰5%èª¤å·®):")
    for axis, actual, pred in [('X', y_test['Disp. X'], y_pred_X), 
                               ('Z', y_test['Disp. Z'], y_pred_Z)]:
        abs_errors = np.abs(actual - pred)
        error_threshold = np.percentile(abs_errors, 95)
        extreme_mask = abs_errors >= error_threshold
        
        if extreme_mask.sum() > 0:
            extreme_rmse = np.sqrt(mean_squared_error(actual[extreme_mask], pred[extreme_mask]))
            max_error = abs_errors.max()
            extreme_count = extreme_mask.sum()
            
            print(f"  {axis}è»¸æ¥µç«¯æƒ…æ³: RMSE={extreme_rmse:.4f} Î¼m, æœ€å¤§èª¤å·®={max_error:.4f} Î¼m, æ¨£æœ¬æ•¸={extreme_count}")
    
    return results

def compare_models_segmented():
    """æ¯”è¼ƒä¸‰ç¨®æ¨¡å‹çš„åˆ†å€æ€§èƒ½"""
    print("ğŸ”¬ è¼‰å…¥è³‡æ–™...")
    data, feature_columns, target_columns = load_and_prepare_data()
    
    print(f"è³‡æ–™å¤§å°: {data.shape}")
    print(f"ç‰¹å¾µæ•¸é‡: {len(feature_columns)}")
    
    # åˆ†å‰²è³‡æ–™
    X = data[feature_columns]
    y = data[target_columns]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    models = {
        'ç·šæ€§å›æ­¸': {
            'X': LinearRegression(),
            'Z': LinearRegression()
        },
        'éš¨æ©Ÿæ£®æ—': {
            'X': RandomForestRegressor(n_estimators=50, random_state=42),
            'Z': RandomForestRegressor(n_estimators=50, random_state=42)
        },
        'æ¢¯åº¦æå‡': {
            'X': GradientBoostingRegressor(n_estimators=50, random_state=42),
            'Z': GradientBoostingRegressor(n_estimators=50, random_state=42)
        }
    }
    
    all_results = {}
    
    for model_name, model_dict in models.items():
        print(f"\n{'='*50}")
        print(f"è¨“ç·´ {model_name} æ¨¡å‹")
        print(f"{'='*50}")
        
        # è¨“ç·´æ¨¡å‹
        model_dict['X'].fit(X_train_scaled, y_train['Disp. X'])
        model_dict['Z'].fit(X_train_scaled, y_train['Disp. Z'])
        
        # é æ¸¬
        y_pred_X = model_dict['X'].predict(X_test_scaled)
        y_pred_Z = model_dict['Z'].predict(X_test_scaled)
        
        # æ•´é«”æ€§èƒ½
        rmse_X = np.sqrt(mean_squared_error(y_test['Disp. X'], y_pred_X))
        rmse_Z = np.sqrt(mean_squared_error(y_test['Disp. Z'], y_pred_Z))
        r2_X = r2_score(y_test['Disp. X'], y_pred_X)
        r2_Z = r2_score(y_test['Disp. Z'], y_pred_Z)
        
        print(f"\næ•´é«”æ€§èƒ½:")
        print(f"Xè»¸ RMSE: {rmse_X:.4f} Î¼m, RÂ²: {r2_X:.4f}")
        print(f"Zè»¸ RMSE: {rmse_Z:.4f} Î¼m, RÂ²: {r2_Z:.4f}")
        print(f"å¹³å‡ RMSE: {(rmse_X + rmse_Z)/2:.4f} Î¼m")
        
        # åˆ†å€åˆ†æ
        segmented_results = segmented_rmse_analysis(X_test, y_test, y_pred_X, y_pred_Z, model_name)
        
        all_results[model_name] = {
            'rmse_X': rmse_X,
            'rmse_Z': rmse_Z,
            'avg_rmse': (rmse_X + rmse_Z)/2,
            'r2_X': r2_X,
            'r2_Z': r2_Z,
            'segmented': segmented_results
        }
    
    # ç¸½çµæ¯”è¼ƒ
    print(f"\n{'='*50}")
    print("æ¨¡å‹ç¸½çµæ¯”è¼ƒ")
    print(f"{'='*50}")
    
    print(f"{'æ¨¡å‹':<10} {'å¹³å‡RMSE(Î¼m)':<15} {'Xè»¸RMSE(Î¼m)':<15} {'Zè»¸RMSE(Î¼m)':<15}")
    print("-" * 60)
    
    for model_name, results in all_results.items():
        print(f"{model_name:<10} {results['avg_rmse']:<15.4f} {results['rmse_X']:<15.4f} {results['rmse_Z']:<15.4f}")
    
    return all_results

if __name__ == "__main__":
    results = compare_models_segmented()
